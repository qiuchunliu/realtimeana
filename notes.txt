1   Exception in thread "main" org.apache.spark.SparkException:
    Only one SparkContext may be running in this JVM (see SPARK-2243).
    To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:

    解决：配置的ssc冲突了，重新捋顺一下就好

2   直接对stream进行rdd处理，不考虑使用mapWithState方法（后续再考虑）

3   存储数据到mysql时，不用考虑太多，做过多计算，直接存，至于展示，那是从数据库调数据的操作